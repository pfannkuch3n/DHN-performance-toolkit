{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Using local configuration\n",
      "ğŸ“‹ Exploring: Analysis 1\n",
      "ğŸ“‚ Data file: X:\\Projekte\\EBC_ACS_JERI_0001_BMWi_TransUrbanNRW\\Students\\Students_Exchange\\rka-lko\\X drive\\work\\2025_07_uesgraphs parquet conversion\\Sim20250722_164922\\Sim20250722_164922_1\\Results\\Sim20250722_164922_1_inputs.gzip\n",
      "Json path: X:\\Projekte\\EBC_ACS_JERI_0001_BMWi_TransUrbanNRW\\Students\\Students_Exchange\\rka-lko\\X drive\\work\\2025_07_uesgraphs parquet conversion\\Sim20250722_164922\\Sim20250722_164922_1\\json\\district_with_demand.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "DHN Metadata Explorer - Simulation Data Investigation\n",
    "====================================================\n",
    "Explores large Dymola simulation files before processing.\n",
    "Helps understand data structure and generate appropriate filters.\n",
    "\n",
    "Usage:\n",
    "    1. Run this after main_analysis.py setup\n",
    "    2. Uses same config and uesgraph\n",
    "    3. Provides overview of available simulation data\n",
    "\"\"\"\n",
    "\n",
    "# Same imports and config as main_analysis.py\n",
    "try:\n",
    "    from config_local import SCENARIOS, DEFAULT_PARAMS\n",
    "    print(\"âœ… Using local configuration\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ config_local.py not found - using template\")\n",
    "    from config_template import SCENARIOS, DEFAULT_PARAMS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# UESGraphs\n",
    "from uesgraphs.uesgraph import UESGraph\n",
    "import uesgraphs.analyze as analyze\n",
    "\n",
    "# Same setup as main_analysis.py\n",
    "scenario_key = \"Scenario 1\"  # Adjust this\n",
    "scenario = SCENARIOS[scenario_key]\n",
    "print(f\"ğŸ“‹ Exploring: {scenario['name']}\")\n",
    "print(f\"ğŸ“‚ Data file: {scenario['data_path']}\")\n",
    "print(f\"Json path: {scenario['json_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read nodes...\n",
      "******\n",
      " input_ids were {'buildings': None, 'nodes': '84dd76a2-6254-4b54-9023-5ec728bbae40', 'pipes': None, 'supplies': None}\n",
      "...finished\n",
      "âœ… Network loaded: 280 nodes, 279 edges\n",
      "ğŸ¢ Buildings in network: 53\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load UESGraph \n",
    "uesgraph = UESGraph()\n",
    "uesgraph.from_json(path=scenario[\"json_path\"], network_type=\"heating\")\n",
    "print(f\"âœ… Network loaded: {len(uesgraph.nodes)} nodes, {len(uesgraph.edges)} edges\")\n",
    "\n",
    "\n",
    "# Get building names from uesgraph (like in get_dataframe())\n",
    "building_names = []\n",
    "for node in uesgraph.nodelist_building:\n",
    "    if not uesgraph.nodes[node][\"is_supply_heating\"]:\n",
    "        building_names.append(uesgraph.nodes[node][\"name\"])\n",
    "print(f\"ğŸ¢ Buildings in network: {len(building_names)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Testing thrift limits for: X:\\Projekte\\EBC_ACS_JERI_0001_BMWi_TransUrbanNRW\\Students\\Students_Exchange\\rka-lko\\X drive\\work\\2025_07_uesgraphs parquet conversion\\Sim20250722_164922\\Sim20250722_164922_1\\Results\\Sim20250722_164922_1_inputs.gzip\n",
      "============================================================\n",
      "ğŸ”„ Trying 16MB limit...\n",
      "âŒ Failed with 16MB: Couldn't deserialize thrift: TProtocolException: Exceeded size limit\n",
      "...\n",
      "ğŸ”„ Trying 100MB limit...\n",
      "âŒ Failed with 100MB: Couldn't deserialize thrift: TProtocolException: Exceeded size limit\n",
      "...\n",
      "ğŸ”„ Trying 500MB limit...\n",
      "âœ… SUCCESS with 500MB limit!\n",
      "ğŸ“Š Total columns: 251,415\n",
      "ğŸ“Š Total rows: 8,761\n",
      "ğŸ“Š File size: 227.1 MB\n",
      "============================================================\n",
      "ğŸ¯ Minimum required limit: 500MB\n",
      "ğŸ“‹ File has 251,415 columns and 8,761 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test_parquet_import_thrift_limits(file_path):\n",
    "    \"\"\"\n",
    "    Test different thrift limits to find minimum required size.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the parquet file\n",
    "    \n",
    "    Returns:\n",
    "        dict: Results of the successful attempt, or None if all fail\n",
    "    \"\"\"\n",
    "    # Try progressively larger thrift limits\n",
    "    limits_to_try = [\n",
    "        {\"size\": \"16MB\",   \"limit\": 16_000_000},      # PyArrow default\n",
    "        {\"size\": \"100MB\",  \"limit\": 100_000_000},     # Conservative increase\n",
    "        {\"size\": \"500MB\",  \"limit\": 500_000_000},     # Current fix\n",
    "        {\"size\": \"1GB\",    \"limit\": 1_000_000_000},   # Large files\n",
    "        {\"size\": \"2GB\",    \"limit\": 2_000_000_000},   # Very large files\n",
    "    ]\n",
    "    \n",
    "    print(f\"ğŸ” Testing thrift limits for: {file_path}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for attempt in limits_to_try:\n",
    "        try:\n",
    "            print(f\"ğŸ”„ Trying {attempt['size']} limit...\")\n",
    "            \n",
    "            parquet_file = pq.ParquetFile(\n",
    "                file_path,\n",
    "                thrift_string_size_limit=attempt['limit'],\n",
    "                thrift_container_size_limit=attempt['limit']\n",
    "            )\n",
    "            \n",
    "            # Extract metadata\n",
    "            all_columns = parquet_file.schema.names\n",
    "            num_rows = parquet_file.metadata.num_rows\n",
    "            file_size_mb = parquet_file.metadata.serialized_size / 1_000_000\n",
    "            \n",
    "            # Success!\n",
    "            print(f\"âœ… SUCCESS with {attempt['size']} limit!\")\n",
    "            print(f\"ğŸ“Š Total columns: {len(all_columns):,}\")\n",
    "            print(f\"ğŸ“Š Total rows: {num_rows:,}\")\n",
    "            print(f\"ğŸ“Š File size: {file_size_mb:.1f} MB\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'limit_used': attempt['limit'],\n",
    "                'limit_size': attempt['size'],\n",
    "                'total_columns': len(all_columns),\n",
    "                'total_rows': num_rows,\n",
    "                'file_size_mb': file_size_mb,\n",
    "                'columns': all_columns\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed with {attempt['size']}: {str(e)[:100]}...\")\n",
    "            continue\n",
    "    \n",
    "    print(\"ğŸš¨ All thrift limits failed!\")\n",
    "    print(\"ğŸ’¡ Consider using alternative parquet engines (fastparquet, pandas)\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# Aufruf\n",
    "result = test_parquet_import_thrift_limits(scenario[\"data_path\"])\n",
    "\n",
    "if result:\n",
    "    print(f\"ğŸ¯ Minimum required limit: {result['limit_size']}\")\n",
    "    print(f\"ğŸ“‹ File has {result['total_columns']:,} columns and {result['total_rows']:,} rows\")\n",
    "else:\n",
    "    print(\"âŒ Could not read file with any thrift limit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ³ MODELICA STRUCTURE ANALYSIS\n",
      "==================================================\n",
      "ğŸ“ networkModel/\n",
      "â”œâ”€â”€ ğŸ¢ DEMAND SIDE\n",
      "â”‚   â”œâ”€â”€ Buildings: 53 found\n",
      "â”‚   â”‚   Examples: ['T179', 'T261', 'T37']\n",
      "â”‚   â”‚   ... +50 more\n",
      "â”‚   â”‚\n",
      "â”‚   â””â”€â”€ Components per building:\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ T_cold_supply (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ T_dhw_supply (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”¥ T_heat_supply (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ allowFlowReversal (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ cp_default (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ dT_Network (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ demand_dhw (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”¥ demand_heat (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ dp_nominal_SS (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ dp_valve_fixed (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ dp_valve_nominal (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ hE_1_1 (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”¥ heatDemand_max (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ m_flow_nominal (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ port_a (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ port_a1 (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ port_a2 (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ port_b (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ port_b1 (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ port_b2 (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ senTem_Flow (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ senTem_Return (53 buildings)\n",
      "â”‚       â”œâ”€â”€ ğŸ”§ simpleSubstationValve (53 buildings)\n",
      "â”‚\n",
      "â”œâ”€â”€ ğŸ­ SUPPLY SIDE\n",
      "â”‚   â”œâ”€â”€ ğŸ“Š T_cold_supply (1 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ“Š T_dhw_supply (1 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ”¥ T_heat_supply (1 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ“Š bou (13 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ“Š cp_default (1 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ“Š dT_Network (1 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ“Š demand_total (17 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ“Š division2 (3 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ“Š dp_nominal (1 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ“Š dp_nominal_pump (1 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ”¥ heatDemand_max_supply (1 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ”¥ heater (29 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ“Š limiter1 (6 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ“Š m_flow_nominal_supply (1 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ“Š per (63 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ“Š port_a (3 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ“Š port_b (3 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ“Š pumHea_central (108 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ“Š realExpression1 (1 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ“Š realExpression2 (1 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ“Š senTem_flow (16 variables)\n",
      "â”‚   â”œâ”€â”€ ğŸ“Š senTem_return (16 variables)\n",
      "â”‚\n",
      "â””â”€â”€ ğŸš° DISTRIBUTION\n",
      "    â””â”€â”€ Pipes: 558 found\n",
      "        â”œâ”€â”€ pipe10171134R\n",
      "        â”œâ”€â”€ pipe11131114\n",
      "        â”œâ”€â”€ pipe12891402R\n",
      "        â””â”€â”€ ... +555 more\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show hierarchical structure of Modelica simulation data to find variables you can use\n",
    "# For example finding the 'senTem_Flow' variable\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def show_structure(result, max_examples=3):\n",
    "    \"\"\"\n",
    "    Show hierarchical structure of Modelica simulation data.\n",
    "    \n",
    "    Args:\n",
    "        result: Result dict from test_parquet_thrift_limits()\n",
    "        max_examples: Maximum examples to show per category\n",
    "    \"\"\"\n",
    "    if not result:\n",
    "        print(\"âŒ No data to analyze\")\n",
    "        return\n",
    "    \n",
    "    all_columns = result['columns']\n",
    "    print(\"ğŸŒ³ MODELICA STRUCTURE ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Parse structure\n",
    "    demand_components = defaultdict(set)\n",
    "    supply_components = defaultdict(set)  \n",
    "    pipe_components = defaultdict(set)\n",
    "    \n",
    "    # Analyze column patterns\n",
    "    for col in all_columns:\n",
    "        parts = col.split('.')\n",
    "        if len(parts) < 3:\n",
    "            continue\n",
    "            \n",
    "        # Demand side analysis\n",
    "        if 'demandT' in col:\n",
    "            # Extract building and component info\n",
    "            demand_match = re.search(r'demandT([^.]+)\\.([^.]+)', col)\n",
    "            if demand_match:\n",
    "                building = f\"T{demand_match.group(1)}\"\n",
    "                component = demand_match.group(2)\n",
    "                demand_components[component].add(building)\n",
    "        \n",
    "        # Supply side analysis  \n",
    "        elif 'supplyT' in col:\n",
    "            supply_match = re.search(r'supplyT[^.]*\\.([^.]+)', col)\n",
    "            if supply_match:\n",
    "                component = supply_match.group(1)\n",
    "                supply_components[component].add(col)\n",
    "                \n",
    "        # Pipe analysis\n",
    "        elif 'pipe' in col.lower():\n",
    "            pipe_match = re.search(r'(pipe[^.]*)', col)\n",
    "            if pipe_match:\n",
    "                pipe_name = pipe_match.group(1)\n",
    "                pipe_components['pipes'].add(pipe_name)\n",
    "    \n",
    "    # Display structure\n",
    "    print(\"ğŸ“ networkModel/\")\n",
    "    print(\"â”œâ”€â”€ ğŸ¢ DEMAND SIDE\")\n",
    "    \n",
    "    if demand_components:\n",
    "        # Show buildings\n",
    "        all_buildings = set()\n",
    "        for buildings in demand_components.values():\n",
    "            all_buildings.update(buildings)\n",
    "        print(f\"â”‚   â”œâ”€â”€ Buildings: {len(all_buildings)} found\")\n",
    "        print(f\"â”‚   â”‚   Examples: {list(all_buildings)[:max_examples]}\")\n",
    "        if len(all_buildings) > max_examples:\n",
    "            print(f\"â”‚   â”‚   ... +{len(all_buildings) - max_examples} more\")\n",
    "        print(\"â”‚   â”‚\")\n",
    "        \n",
    "        # Show components per building\n",
    "        print(\"â”‚   â””â”€â”€ Components per building:\")\n",
    "        for component, buildings in sorted(demand_components.items()):\n",
    "            icon = \"ğŸ’§\" if \"pump\" in component.lower() else \"ğŸ”¥\" if \"heat\" in component.lower() else \"ğŸ”§\"\n",
    "            print(f\"â”‚       â”œâ”€â”€ {icon} {component} ({len(buildings)} buildings)\")\n",
    "    \n",
    "    print(\"â”‚\")\n",
    "    print(\"â”œâ”€â”€ ğŸ­ SUPPLY SIDE\")\n",
    "    if supply_components:\n",
    "        for component, vars in sorted(supply_components.items()):\n",
    "            icon = \"ğŸ”¥\" if any(x in component.lower() for x in [\"boiler\", \"heat\"]) else \"ğŸ“Š\"\n",
    "            print(f\"â”‚   â”œâ”€â”€ {icon} {component} ({len(vars)} variables)\")\n",
    "    else:\n",
    "        print(\"â”‚   â””â”€â”€ No supply components found\")\n",
    "    \n",
    "    print(\"â”‚\")  \n",
    "    print(\"â””â”€â”€ ğŸš° DISTRIBUTION\")\n",
    "    if pipe_components.get('pipes'):\n",
    "        pipe_count = len(pipe_components['pipes'])\n",
    "        print(f\"    â””â”€â”€ Pipes: {pipe_count} found\")\n",
    "        if pipe_count <= max_examples:\n",
    "            for pipe in list(pipe_components['pipes'])[:max_examples]:\n",
    "                print(f\"        â”œâ”€â”€ {pipe}\")\n",
    "        else:\n",
    "            for pipe in list(pipe_components['pipes'])[:max_examples]:\n",
    "                print(f\"        â”œâ”€â”€ {pipe}\")\n",
    "            print(f\"        â””â”€â”€ ... +{pipe_count - max_examples} more\")\n",
    "    else:\n",
    "        print(\"    â””â”€â”€ No pipe components found\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "\n",
    "show_structure(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ SENSOR TEMPERATURE SEARCH:\n",
      "ğŸ” Looking for physical variables of: senTem_Flow\n",
      "============================================================\n",
      "âœ… senTem_Flow.T: 106 found\n",
      "   Examples: ['networkModel.demandT4.senTem_Flow.T', 'networkModel.demandT4.hE_1_1.senTem_Flow.T', 'networkModel.demandT5.senTem_Flow.T', 'networkModel.demandT5.hE_1_1.senTem_Flow.T', 'networkModel.demandT12.senTem_Flow.T']\n",
      "   Mask: networkModel.demandT{name_bldg}.senTem_Flow.T$\n",
      "\n",
      "âœ… senTem_Flow.p: 212 found\n",
      "   Examples: ['networkModel.demandT4.senTem_Flow.port_a.p', 'networkModel.demandT4.senTem_Flow.port_b.p', 'networkModel.demandT4.hE_1_1.senTem_Flow.port_a.p', 'networkModel.demandT4.hE_1_1.senTem_Flow.port_b.p', 'networkModel.demandT5.senTem_Flow.port_a.p']\n",
      "   Mask: networkModel.demandT{name_bldg}.senTem_Flow.p$\n",
      "\n",
      "âŒ senTem_Flow.m_flow: Not found\n",
      "\n",
      "ğŸ” Looking for physical variables of: senTem_Return\n",
      "============================================================\n",
      "âœ… senTem_Return.T: 53 found\n",
      "   Examples: ['networkModel.demandT4.senTem_Return.T', 'networkModel.demandT5.senTem_Return.T', 'networkModel.demandT12.senTem_Return.T', 'networkModel.demandT15.senTem_Return.T', 'networkModel.demandT24.senTem_Return.T']\n",
      "   Mask: networkModel.demandT{name_bldg}.senTem_Return.T$\n",
      "\n",
      "âœ… senTem_Return.p: 106 found\n",
      "   Examples: ['networkModel.demandT4.senTem_Return.port_a.p', 'networkModel.demandT4.senTem_Return.port_b.p', 'networkModel.demandT5.senTem_Return.port_a.p', 'networkModel.demandT5.senTem_Return.port_b.p', 'networkModel.demandT12.senTem_Return.port_a.p']\n",
      "   Mask: networkModel.demandT{name_bldg}.senTem_Return.p$\n",
      "\n",
      "âŒ senTem_Return.m_flow: Not found\n",
      "\n",
      "ğŸ“ READY-TO-USE MASKS:\n",
      "==============================\n",
      "SENTEM_FLOW_T_MASK = 'networkModel.demandT{name_bldg}.senTem_Flow.T$'\n",
      "SENTEM_FLOW_P_MASK = 'networkModel.demandT{name_bldg}.senTem_Flow.p$'\n",
      "SENTEM_RETURN_T_MASK = 'networkModel.demandT{name_bldg}.senTem_Return.T$'\n",
      "SENTEM_RETURN_P_MASK = 'networkModel.demandT{name_bldg}.senTem_Return.p$'\n",
      "\n",
      "# Most likely what you want:\n",
      "FLOW_TEMP_MASK = 'networkModel.demandT{name_bldg}.senTem_Flow.T$'\n",
      "RETURN_TEMP_MASK = 'networkModel.demandT{name_bldg}.senTem_Return.T$'\n"
     ]
    }
   ],
   "source": [
    "# For identified variables, find specific physical variables like 'senTem_Flow.T', 'senTem_Return.p', etc. \n",
    "# And generate ready-to-use masks for them.\n",
    "def find_specific_variables(result, base_variable, endings=['T', 'p', 'm_flow'], max_examples=5):\n",
    "    \"\"\"\n",
    "    Find specific physical variables (not configuration parameters).\n",
    "    \n",
    "    Args:\n",
    "        result: Result dict from test_parquet_thrift_limits()\n",
    "        base_variable: Base variable name (e.g., 'senTem_Flow')\n",
    "        endings: Physical variable endings to look for\n",
    "        max_examples: Maximum examples to show\n",
    "    \"\"\"\n",
    "    if not result:\n",
    "        return None\n",
    "    \n",
    "    all_columns = result['columns']\n",
    "    print(f\"ğŸ” Looking for physical variables of: {base_variable}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    found_variables = {}\n",
    "    \n",
    "    for ending in endings:\n",
    "        pattern = f\"{base_variable}.{ending}\"\n",
    "        matching_columns = [col for col in all_columns if pattern in col and col.endswith(f'.{ending}')]\n",
    "        \n",
    "        if matching_columns:\n",
    "            print(f\"âœ… {base_variable}.{ending}: {len(matching_columns)} found\")\n",
    "            print(f\"   Examples: {matching_columns[:max_examples]}\")\n",
    "            \n",
    "            # Generate mask\n",
    "            mask = f\"networkModel.demandT{{name_bldg}}.{base_variable}.{ending}$\"\n",
    "            print(f\"   Mask: {mask}\")\n",
    "            \n",
    "            found_variables[f\"{base_variable}_{ending}\"] = {\n",
    "                'mask': mask,\n",
    "                'count': len(matching_columns),\n",
    "                'examples': matching_columns[:max_examples]\n",
    "            }\n",
    "        else:\n",
    "            print(f\"âŒ {base_variable}.{ending}: Not found\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    return found_variables\n",
    "\n",
    "\n",
    "# Quick usage\n",
    "print(\"ğŸ¯ SENSOR TEMPERATURE SEARCH:\")\n",
    "flow_results = find_specific_variables(result, 'senTem_Flow')\n",
    "return_results = find_specific_variables(result, 'senTem_Return')\n",
    "\n",
    "# Show ready-to-use masks\n",
    "if flow_results or return_results:\n",
    "    print(\"ğŸ“ READY-TO-USE MASKS:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Combine results\n",
    "    all_results = {}\n",
    "    if flow_results:\n",
    "        all_results.update(flow_results)\n",
    "    if return_results:\n",
    "        all_results.update(return_results)\n",
    "    \n",
    "    for var_name, info in all_results.items():\n",
    "        mask_name = f\"{var_name.upper()}_MASK\"\n",
    "        print(f\"{mask_name} = '{info['mask']}'\")\n",
    "    \n",
    "    print(\"\\n# Most likely what you want:\")\n",
    "    if 'senTem_Flow_T' in all_results:\n",
    "        print(\"FLOW_TEMP_MASK = 'networkModel.demandT{name_bldg}.senTem_Flow.T$'\")\n",
    "    if 'senTem_Return_T' in all_results:\n",
    "        print(\"RETURN_TEMP_MASK = 'networkModel.demandT{name_bldg}.senTem_Return.T$'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: X:\\Projekte\\EBC_ACS_JERI_0001_BMWi_TransUrbanNRW\\Students\\Students_Exchange\\rka-lko\\X drive\\work\\2025_07_uesgraphs parquet conversion\\Sim20250722_164922\\Sim20250722_164922_1\\Results\\Sim20250722_164922_1_inputs.gzip\n"
     ]
    }
   ],
   "source": [
    "#Use this masks to load results\n",
    "\n",
    "# Data Loading Functions from analysis.ipynb\n",
    "def get_dataframe(mask, file_path, uesgraph):\n",
    "    \"\"\"Load data for a specific mask pattern\"\"\"\n",
    "    filter_list = []\n",
    "    for node in uesgraph.nodelist_building:\n",
    "        if not uesgraph.nodes[node][\"is_supply_heating\"]:\n",
    "            name_bldg = uesgraph.nodes[node][\"name\"]\n",
    "            filter_pattern = mask.format(name_bldg=name_bldg)\n",
    "            filter_list.append(filter_pattern)\n",
    "    \n",
    "    df = analyze.process_simulation_result(file_path=file_path, filter_list=filter_list)\n",
    "    df = analyze.prepare_DataFrame(\n",
    "        df, \n",
    "        base_date=datetime.strptime(DEFAULT_PARAMS[\"start_date\"], \"%Y-%m-%d\"), \n",
    "        end_date=datetime.strptime(DEFAULT_PARAMS[\"end_date\"], \"%Y-%m-%d\"),\n",
    "        time_interval=DEFAULT_PARAMS[\"time_interval\"]\n",
    "    )\n",
    "    \n",
    "    # Simplify column names\n",
    "    import re\n",
    "    pattern = re.compile(r'T([^.]+)')\n",
    "    new_columns = []\n",
    "    for col in df.columns:\n",
    "        match = pattern.search(col)\n",
    "        if match:\n",
    "            new_columns.append(f\"T{match.group(1)}\")\n",
    "        else:\n",
    "            new_columns.append(col)\n",
    "    df.columns = new_columns\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "flow_temp_mask = \"networkModel.demandT{name_bldg}.senTem_Flow.T$\"\n",
    "return_temp_mask = \"networkModel.demandT{name_bldg}.senTem_Return.T$\"\n",
    "df = get_dataframe(flow_temp_mask, scenario[\"data_path\"], uesgraph)\n",
    "# Display basic info\n",
    "print(\"ğŸ“Š DataFrame loaded:\"\n",
    "      f\" {df.shape[0]:,} rows, {df.shape[1]:,} columns\")\n",
    "# Display first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uesgraphs1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
