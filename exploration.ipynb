{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using local configuration\n",
      "📋 Exploring: Analysis 1\n",
      "📂 Data file: X:\\Projekte\\EBC_ACS_JERI_0001_BMWi_TransUrbanNRW\\Students\\Students_Exchange\\rka-lko\\X drive\\work\\2025_07_uesgraphs parquet conversion\\Sim20250722_164922\\Sim20250722_164922_1\\Results\\Sim20250722_164922_1_inputs.gzip\n",
      "Json path: X:\\Projekte\\EBC_ACS_JERI_0001_BMWi_TransUrbanNRW\\Students\\Students_Exchange\\rka-lko\\X drive\\work\\2025_07_uesgraphs parquet conversion\\Sim20250722_164922\\Sim20250722_164922_1\\json\\district_with_demand.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "DHN Metadata Explorer - Simulation Data Investigation\n",
    "====================================================\n",
    "Explores large Dymola simulation files before processing.\n",
    "Helps understand data structure and generate appropriate filters.\n",
    "\n",
    "Usage:\n",
    "    1. Run this after main_analysis.py setup\n",
    "    2. Uses same config and uesgraph\n",
    "    3. Provides overview of available simulation data\n",
    "\"\"\"\n",
    "\n",
    "# Same imports and config as main_analysis.py\n",
    "try:\n",
    "    from config_local import SCENARIOS, DEFAULT_PARAMS\n",
    "    print(\"✅ Using local configuration\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ config_local.py not found - using template\")\n",
    "    from config_template import SCENARIOS, DEFAULT_PARAMS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# UESGraphs\n",
    "from uesgraphs.uesgraph import UESGraph\n",
    "import uesgraphs.analyze as analyze\n",
    "\n",
    "# Same setup as main_analysis.py\n",
    "scenario_key = \"Scenario 1\"  # Adjust this\n",
    "scenario = SCENARIOS[scenario_key]\n",
    "print(f\"📋 Exploring: {scenario['name']}\")\n",
    "print(f\"📂 Data file: {scenario['data_path']}\")\n",
    "print(f\"Json path: {scenario['json_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read nodes...\n",
      "******\n",
      " input_ids were {'buildings': None, 'nodes': '84dd76a2-6254-4b54-9023-5ec728bbae40', 'pipes': None, 'supplies': None}\n",
      "...finished\n",
      "✅ Network loaded: 280 nodes, 279 edges\n",
      "🏢 Buildings in network: 53\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load UESGraph \n",
    "uesgraph = UESGraph()\n",
    "uesgraph.from_json(path=scenario[\"json_path\"], network_type=\"heating\")\n",
    "print(f\"✅ Network loaded: {len(uesgraph.nodes)} nodes, {len(uesgraph.edges)} edges\")\n",
    "\n",
    "\n",
    "# Get building names from uesgraph (like in get_dataframe())\n",
    "building_names = []\n",
    "for node in uesgraph.nodelist_building:\n",
    "    if not uesgraph.nodes[node][\"is_supply_heating\"]:\n",
    "        building_names.append(uesgraph.nodes[node][\"name\"])\n",
    "print(f\"🏢 Buildings in network: {len(building_names)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Testing thrift limits for: X:\\Projekte\\EBC_ACS_JERI_0001_BMWi_TransUrbanNRW\\Students\\Students_Exchange\\rka-lko\\X drive\\work\\2025_07_uesgraphs parquet conversion\\Sim20250722_164922\\Sim20250722_164922_1\\Results\\Sim20250722_164922_1_inputs.gzip\n",
      "============================================================\n",
      "🔄 Trying 16MB limit...\n",
      "❌ Failed with 16MB: Couldn't deserialize thrift: TProtocolException: Exceeded size limit\n",
      "...\n",
      "🔄 Trying 100MB limit...\n",
      "❌ Failed with 100MB: Couldn't deserialize thrift: TProtocolException: Exceeded size limit\n",
      "...\n",
      "🔄 Trying 500MB limit...\n",
      "✅ SUCCESS with 500MB limit!\n",
      "📊 Total columns: 251,415\n",
      "📊 Total rows: 8,761\n",
      "📊 File size: 227.1 MB\n",
      "============================================================\n",
      "🎯 Minimum required limit: 500MB\n",
      "📋 File has 251,415 columns and 8,761 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test_parquet_import_thrift_limits(file_path):\n",
    "    \"\"\"\n",
    "    Test different thrift limits to find minimum required size.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the parquet file\n",
    "    \n",
    "    Returns:\n",
    "        dict: Results of the successful attempt, or None if all fail\n",
    "    \"\"\"\n",
    "    # Try progressively larger thrift limits\n",
    "    limits_to_try = [\n",
    "        {\"size\": \"16MB\",   \"limit\": 16_000_000},      # PyArrow default\n",
    "        {\"size\": \"100MB\",  \"limit\": 100_000_000},     # Conservative increase\n",
    "        {\"size\": \"500MB\",  \"limit\": 500_000_000},     # Current fix\n",
    "        {\"size\": \"1GB\",    \"limit\": 1_000_000_000},   # Large files\n",
    "        {\"size\": \"2GB\",    \"limit\": 2_000_000_000},   # Very large files\n",
    "    ]\n",
    "    \n",
    "    print(f\"🔍 Testing thrift limits for: {file_path}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for attempt in limits_to_try:\n",
    "        try:\n",
    "            print(f\"🔄 Trying {attempt['size']} limit...\")\n",
    "            \n",
    "            parquet_file = pq.ParquetFile(\n",
    "                file_path,\n",
    "                thrift_string_size_limit=attempt['limit'],\n",
    "                thrift_container_size_limit=attempt['limit']\n",
    "            )\n",
    "            \n",
    "            # Extract metadata\n",
    "            all_columns = parquet_file.schema.names\n",
    "            num_rows = parquet_file.metadata.num_rows\n",
    "            file_size_mb = parquet_file.metadata.serialized_size / 1_000_000\n",
    "            \n",
    "            # Success!\n",
    "            print(f\"✅ SUCCESS with {attempt['size']} limit!\")\n",
    "            print(f\"📊 Total columns: {len(all_columns):,}\")\n",
    "            print(f\"📊 Total rows: {num_rows:,}\")\n",
    "            print(f\"📊 File size: {file_size_mb:.1f} MB\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'limit_used': attempt['limit'],\n",
    "                'limit_size': attempt['size'],\n",
    "                'total_columns': len(all_columns),\n",
    "                'total_rows': num_rows,\n",
    "                'file_size_mb': file_size_mb,\n",
    "                'columns': all_columns\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed with {attempt['size']}: {str(e)[:100]}...\")\n",
    "            continue\n",
    "    \n",
    "    print(\"🚨 All thrift limits failed!\")\n",
    "    print(\"💡 Consider using alternative parquet engines (fastparquet, pandas)\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# Aufruf\n",
    "result = test_parquet_import_thrift_limits(scenario[\"data_path\"])\n",
    "\n",
    "if result:\n",
    "    print(f\"🎯 Minimum required limit: {result['limit_size']}\")\n",
    "    print(f\"📋 File has {result['total_columns']:,} columns and {result['total_rows']:,} rows\")\n",
    "else:\n",
    "    print(\"❌ Could not read file with any thrift limit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Exploring simulation data structure...\n",
      "\n",
      "🏢 BUILDINGS FOUND:\n",
      "   Count: 53\n",
      "   Sample: ['T24', 'T41', 'T195', 'T138', 'T179', 'T261', 'T168', 'T37', 'T66', 'T4']\n",
      "   ... +43 more\n",
      "\n",
      "🔧 COMMON VARIABLES:\n",
      "   Most frequent:\n",
      "     T: 21422x\n",
      "     m_flow: 17121x\n",
      "     Q_flow: 16796x\n",
      "     p: 15234x\n",
      "     h_outflow: 12443x\n",
      "     length: 10044x\n",
      "     d_in: 7254x\n",
      "     nParallel: 7254x\n",
      "     d_out: 6696x\n",
      "     m_flow_nominal: 6114x\n",
      "\n",
      "💧 PUMP VARIABLES:\n",
      "   Found: 1 pump-related variables\n",
      "   Examples:\n",
      "     networkModel.supplyT284.dp_nominal_pump\n",
      "\n",
      "✅ Exploration completed!\n",
      "💾 Found 53 buildings, 1 pump variables\n"
     ]
    }
   ],
   "source": [
    "def explore_simulation_metadata(result, max_display=10):\n",
    "    \"\"\"\n",
    "    Quick overview of simulation data structure.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to simulation file\n",
    "        max_display: Maximum items to show per category\n",
    "    \n",
    "    Returns:\n",
    "        dict: Basic metadata info\n",
    "    \"\"\"\n",
    "    print(\"🔍 Exploring simulation data structure...\")\n",
    "    \n",
    "    if not result:\n",
    "        return None\n",
    "    \n",
    "    all_columns = result['columns']\n",
    "    print()\n",
    "    \n",
    "    # 1. Find buildings in simulation\n",
    "    print(\"🏢 BUILDINGS FOUND:\")\n",
    "    building_pattern = re.compile(r'demandT([^.]+)')\n",
    "    sim_buildings = set()\n",
    "    for col in all_columns:\n",
    "        match = building_pattern.search(col)\n",
    "        if match:\n",
    "            sim_buildings.add(f\"T{match.group(1)}\")\n",
    "    \n",
    "    print(f\"   Count: {len(sim_buildings)}\")\n",
    "    print(f\"   Sample: {list(sim_buildings)[:max_display]}\")\n",
    "    if len(sim_buildings) > max_display:\n",
    "        print(f\"   ... +{len(sim_buildings) - max_display} more\")\n",
    "    print()\n",
    "    \n",
    "    # 2. Find common variables\n",
    "    print(\"🔧 COMMON VARIABLES:\")\n",
    "    from collections import Counter\n",
    "    var_types = Counter()\n",
    "    for col in all_columns:\n",
    "        if '.' in col:\n",
    "            var_name = col.split('.')[-1]\n",
    "            var_types[var_name] += 1\n",
    "    \n",
    "    print(\"   Most frequent:\")\n",
    "    for var, count in var_types.most_common(max_display):\n",
    "        print(f\"     {var}: {count}x\")\n",
    "    print()\n",
    "    \n",
    "    # 3. Pump variables (user's main interest)\n",
    "    print(\"💧 PUMP VARIABLES:\")\n",
    "    pump_vars = [col for col in all_columns if 'pump' in col.lower()]\n",
    "    print(f\"   Found: {len(pump_vars)} pump-related variables\")\n",
    "    if pump_vars:\n",
    "        print(\"   Examples:\")\n",
    "        for var in pump_vars[:max_display]:\n",
    "            print(f\"     {var}\")\n",
    "        if len(pump_vars) > max_display:\n",
    "            print(f\"     ... +{len(pump_vars) - max_display} more\")\n",
    "    print()\n",
    "    \n",
    "    return {\n",
    "        'buildings': sim_buildings,\n",
    "        'var_types': var_types,\n",
    "        'pump_vars': pump_vars,\n",
    "        'total_columns': result['total_columns'],\n",
    "        'total_rows': result['total_rows']\n",
    "    }\n",
    "\n",
    "\n",
    "# Aufruf\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "metadata = explore_simulation_metadata(result)\n",
    "\n",
    "if metadata:\n",
    "    print(\"✅ Exploration completed!\")\n",
    "    print(f\"💾 Found {len(metadata['buildings'])} buildings, {len(metadata['pump_vars'])} pump variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Exploring simulation data structure...\n",
      "\n",
      "🏢 BUILDINGS FOUND:\n",
      "   Count: 53\n",
      "   Sample: ['T24', 'T41', 'T195', 'T138', 'T179', 'T261', 'T168', 'T37', 'T66', 'T4']\n",
      "   ... +43 more\n",
      "\n",
      "🏗️ SYSTEM COMPONENTS:\n",
      "   Demand variables: 17879\n",
      "     Examples: ['networkModel.supplyT284.heatDemand_max_supply', 'networkModel.supplyT284.demand_total.nout', 'networkModel.supplyT284.demand_total.tableOnFile']\n",
      "   Supply variables: 765\n",
      "     Examples: ['networkModel.supplyT284.cp_default', 'networkModel.supplyT284.m_flow_nominal_supply', 'networkModel.supplyT284.dp_nominal']\n",
      "   Pipe variables: 233244\n",
      "     Examples: ['networkModel.pipe10011002.allowFlowReversal', 'networkModel.pipe10011002.m_flow_nominal', 'networkModel.pipe10011002.m_flow_small']\n",
      "\n",
      "💧 PUMP VARIABLES:\n",
      "   Found: 1 pump-related variables\n",
      "   Examples:\n",
      "     networkModel.supplyT284.dp_nominal_pump\n",
      "\n",
      "✅ Exploration completed!\n",
      "💾 Found 53 buildings, 1 pump variables\n",
      "💾 Components: 17879 demand, 765 supply, 233244 pipe variables\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def analyze_buildings(all_columns, max_display=10):\n",
    "    \"\"\"Analyze buildings found in simulation data.\"\"\"\n",
    "    print(\"🏢 BUILDINGS FOUND:\")\n",
    "    building_pattern = re.compile(r'demandT([^.]+)')\n",
    "    sim_buildings = set()\n",
    "    for col in all_columns:\n",
    "        match = building_pattern.search(col)\n",
    "        if match:\n",
    "            sim_buildings.add(f\"T{match.group(1)}\")\n",
    "    \n",
    "    print(f\"   Count: {len(sim_buildings)}\")\n",
    "    print(f\"   Sample: {list(sim_buildings)[:max_display]}\")\n",
    "    if len(sim_buildings) > max_display:\n",
    "        print(f\"   ... +{len(sim_buildings) - max_display} more\")\n",
    "    print()\n",
    "    \n",
    "    return sim_buildings\n",
    "\n",
    "def analyze_system_components(all_columns, max_display=10):\n",
    "    \"\"\"Analyze demand, supply and pipe variables.\"\"\"\n",
    "    print(\"🏗️ SYSTEM COMPONENTS:\")\n",
    "    \n",
    "    # Count by component type\n",
    "    demand_vars = [col for col in all_columns if 'demand' in col.lower()]\n",
    "    supply_vars = [col for col in all_columns if 'supply' in col.lower()]  \n",
    "    pipe_vars = [col for col in all_columns if 'pipe' in col.lower()]\n",
    "    \n",
    "    print(f\"   Demand variables: {len(demand_vars)}\")\n",
    "    if demand_vars:\n",
    "        print(f\"     Examples: {demand_vars[:3]}\")\n",
    "    \n",
    "    print(f\"   Supply variables: {len(supply_vars)}\")\n",
    "    if supply_vars:\n",
    "        print(f\"     Examples: {supply_vars[:3]}\")\n",
    "        \n",
    "    print(f\"   Pipe variables: {len(pipe_vars)}\")\n",
    "    if pipe_vars:\n",
    "        print(f\"     Examples: {pipe_vars[:3]}\")\n",
    "    print()\n",
    "    \n",
    "    return {\n",
    "        'demand': demand_vars,\n",
    "        'supply': supply_vars,\n",
    "        'pipes': pipe_vars\n",
    "    }\n",
    "\n",
    "def analyze_pump_variables(all_columns, max_display=10):\n",
    "    \"\"\"Analyze pump-related variables.\"\"\"\n",
    "    print(\"💧 PUMP VARIABLES:\")\n",
    "    pump_vars = [col for col in all_columns if 'pump' in col.lower()]\n",
    "    print(f\"   Found: {len(pump_vars)} pump-related variables\")\n",
    "    if pump_vars:\n",
    "        print(\"   Examples:\")\n",
    "        for var in pump_vars[:max_display]:\n",
    "            print(f\"     {var}\")\n",
    "        if len(pump_vars) > max_display:\n",
    "            print(f\"     ... +{len(pump_vars) - max_display} more\")\n",
    "    print()\n",
    "    \n",
    "    return pump_vars\n",
    "\n",
    "def explore_simulation_metadata(result, max_display=10):\n",
    "    \"\"\"\n",
    "    Quick overview of simulation data structure.\n",
    "    \n",
    "    Args:\n",
    "        result: Result dict from test_parquet_thrift_limits()\n",
    "        max_display: Maximum items to show per category\n",
    "    \n",
    "    Returns:\n",
    "        dict: Basic metadata info\n",
    "    \"\"\"\n",
    "    print(\"🔍 Exploring simulation data structure...\")\n",
    "    \n",
    "    if not result:\n",
    "        return None\n",
    "    \n",
    "    all_columns = result['columns']\n",
    "    print()\n",
    "    \n",
    "    # Use the three analysis functions\n",
    "    buildings = analyze_buildings(all_columns, max_display)\n",
    "    components = analyze_system_components(all_columns, max_display) \n",
    "    pump_vars = analyze_pump_variables(all_columns, max_display)\n",
    "    \n",
    "    return {\n",
    "        'buildings': buildings,\n",
    "        'components': components,\n",
    "        'pump_vars': pump_vars,\n",
    "        'total_columns': result['total_columns'],\n",
    "        'total_rows': result['total_rows']\n",
    "    }\n",
    "\n",
    "# Aufruf\n",
    "metadata = explore_simulation_metadata(result)\n",
    "\n",
    "if metadata:\n",
    "    print(\"✅ Exploration completed!\")\n",
    "    print(f\"💾 Found {len(metadata['buildings'])} buildings, {len(metadata['pump_vars'])} pump variables\")\n",
    "    print(f\"💾 Components: {len(metadata['components']['demand'])} demand, {len(metadata['components']['supply'])} supply, {len(metadata['components']['pipes'])} pipe variables\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uesgraphs1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
